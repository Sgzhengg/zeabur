import os
import uuid
import shutil
import zipfile
import traceback
from pathlib import Path
from typing import List

from fastapi import FastAPI, UploadFile, Form, HTTPException, File
from fastapi.middleware.cors import CORSMiddleware
from llama_parse import LlamaParse
from langchain_text_splitters import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient, models
from flashrank import Ranker, RerankRequest

# --- 1. ç¯å¢ƒå˜é‡è¯»å– ---
LLAMA_CLOUD_API_KEY = os.getenv("LLAMA_CLOUD_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

COLLECTION_NAME = "telecom_collection_v2"

print(f"DEBUG CONFIG: URL={QDRANT_URL}")

# --- 2. åˆå§‹åŒ– Re-ranker ---
print("â³ Initializing FlashRank Reranker...")
reranker = Ranker(model_name="ms-marco-MiniLM-L-12-v2", cache_dir="/tmp/flashrank_cache")
print("âœ… Reranker initialized!")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

if not QDRANT_URL:
    raise ValueError("âŒ Fatal Error: QDRANT_URL is missing!")

client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY, prefer_grpc=False)

@app.on_event("startup")
def startup_event():
    print(f"ğŸš€ Connecting to Qdrant at: {QDRANT_URL} ...")
    try:
        collections = client.get_collections()
        print(f"âœ… Connected! Found {len(collections.collections)} collections.")
    except Exception as e:
        print(f"âŒ Connection Failed! Error: {e}")

@app.get("/")
def health_check():
    return {"status": "ok", "service": "Telecom Ingest API Optimized V2"}

# --- è¾…åŠ©å‡½æ•° ---
def extract_zip(zip_path: str, extract_to: str):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

def guess_doc_type(filename: str) -> str:
    main_keywords = ["é€šçŸ¥", "å…¬å‘Š", "ç®¡ç†åŠæ³•", "è§„å®š", "ä¸»ä»¶", "æ­£æ–‡"]
    if any(k in filename for k in main_keywords):
        return "main"
    return "attachment"

@app.post("/ingest")
async def ingest_package(file: UploadFile = File(...), package_id: str = Form(None)):
    """å…¥åº“æ¥å£ï¼šæ”¯æŒ ZIP åŒ…ï¼Œé’ˆå¯¹ç”µä¿¡æ–‡æ¡£ä¼˜åŒ–"""
    if not LLAMA_CLOUD_API_KEY:
         raise HTTPException(status_code=500, detail="LLAMA_CLOUD_API_KEY not set.")

    group_id = package_id if package_id else str(uuid.uuid4())
    base_tmp_dir = f"/tmp/ingest_{group_id}"
    os.makedirs(base_tmp_dir, exist_ok=True)
    upload_path = f"{base_tmp_dir}/{file.filename}"
    
    try:
        content = await file.read()
        with open(upload_path, "wb") as f:
            f.write(content)
        
        files_to_process = []
        if file.filename.lower().endswith(".zip"):
            print(f"ğŸ“¦ Detected ZIP package: {file.filename}")
            extract_dir = f"{base_tmp_dir}/extracted"
            extract_zip(upload_path, extract_dir)
            for root, dirs, files in os.walk(extract_dir):
                for fname in files:
                    if fname.startswith(".") or "__MACOSX" in root: continue
                    files_to_process.append(os.path.join(root, fname))
        else:
            files_to_process.append(upload_path)

        parser = LlamaParse(
            api_key=LLAMA_CLOUD_API_KEY,
            result_type="markdown",
            premium_mode=True, 
            verbose=True,
            parsing_instruction="è¿™æ˜¯ä¸€ä¸ªç”µä¿¡è¿è¥å•†çš„æ”¿ç­–æ–‡æ¡£ï¼ŒåŒ…å«å¤§é‡å¤æ‚çš„åµŒå¥—è¡¨æ ¼ã€‚è¯·å°½å¯èƒ½ä¿ç•™è¡¨æ ¼çš„ç»“æ„ï¼Œä¸è¦é—æ¼ä»»ä½•æ•°å­—ã€‚å¦‚æœè¡¨æ ¼è·¨é¡µï¼Œè¯·å°†å…¶åˆå¹¶ã€‚"
        )

        total_chunks = 0
        all_points = [] 

        for file_path in files_to_process:
            fname = os.path.basename(file_path)
            doc_type = guess_doc_type(fname)
            print(f"ğŸ“„ Parsing ({doc_type}): {fname}")
            
            try:
                documents = await parser.aload_data(file_path)
            except Exception as parse_error:
                print(f"âŒ Parse Error on {fname}: {parse_error}")
                continue

            if not documents: 
                print(f"âš ï¸ Warning: No text found in {fname}")
                continue
                
            markdown_text = documents[0].text
            
            # åˆ‡ç‰‡è®¾ç½®ï¼š2000/500
            splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)
            chunks = splitter.split_text(markdown_text)
            
            for i, chunk_text in enumerate(chunks):
                all_points.append({
                    "content": chunk_text,
                    "metadata": {
                        "group_id": group_id,
                        "filename": fname,
                        "doc_type": doc_type,
                        "chunk_index": i,
                        "source_package": file.filename
                    }
                })
            total_chunks += len(chunks)

        if total_chunks == 0:
            return {"status": "error", "msg": "No documents parsed."}

        if all_points:
            print(f"ğŸ’¾ Upserting {len(all_points)} chunks...")
            texts = [p["content"] for p in all_points]
            metadatas = [p["metadata"] for p in all_points]
            ids = [str(uuid.uuid4()) for _ in all_points]

            client.add(
                collection_name=COLLECTION_NAME,
                documents=texts,
                metadata=metadatas,
                ids=ids
            )
        
        return {"status": "success", "group_id": group_id, "chunks": total_chunks}
        
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if os.path.exists(base_tmp_dir):
            shutil.rmtree(base_tmp_dir)

@app.post("/delete")
async def delete_package(target_id: str = Form(..., description="å¡«å…¥ group_id æˆ– file_id")):
    try:
        if not client.collection_exists(COLLECTION_NAME):
             return {"status": "skipped", "msg": "Collection does not exist."}

        client.delete(
            collection_name=COLLECTION_NAME,
            points_selector=models.FilterSelector(
                filter=models.Filter(
                    must=[models.FieldCondition(key="group_id", match=models.MatchValue(value=target_id))]
                )
            )
        )
        client.delete(
            collection_name=COLLECTION_NAME,
            points_selector=models.FilterSelector(
                filter=models.Filter(
                    must=[models.FieldCondition(key="file_id", match=models.MatchValue(value=target_id))]
                )
            )
        )
        return {"status": "deleted", "target_id": target_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/reset")
async def reset_database():
    try:
        client.delete_collection(COLLECTION_NAME)
        return {"status": "success", "msg": "Collection deleted."}
    except Exception as e:
        return {"status": "success", "msg": "Collection already clear."}

@app.post("/search")
async def search_docs(query: str = Form(...), limit: int = 5):
    try:
        if not client.collection_exists(COLLECTION_NAME):
            return []

        print(f"ğŸ” Searching for: {query}")
        
        # ğŸŸ¢ æ ¸å¿ƒä¿®æ”¹ï¼šå‘é‡åˆç­›æ‰©å¤§åˆ° 300 æ¡
        search_result = client.query(
            collection_name=COLLECTION_NAME,
            query_text=query,
            limit=300 
        )
        
        if not search_result:
            return []

        passages = [
            {"id": str(res.id), "text": res.document, "meta": res.metadata}
            for res in search_result
        ]

        # FlashRank é‡æ’åº
        rerank_request = RerankRequest(query=query, passages=passages)
        ranked_results = reranker.rerank(rerank_request)

        # æˆªå–æœ€ç»ˆè¿”å›æ•°é‡
        top_results = ranked_results[:limit]
        
        return [
            {
                "content": res["text"],
                "score": float(res["score"]),
                "metadata": res["meta"]
            } 
            for res in top_results
        ]

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))